{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4447ca59-9eab-478c-8572-7e925f1ba16b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pyarrow==8.0.0\n",
      "  Downloading pyarrow-8.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting fsspec==2023.5.0\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting huggingface-hub==0.12.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting datasets==2.4.0\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers==4.20.1\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl.metadata (77 kB)\n",
      "Collecting tokenizers==0.11.6\n",
      "  Downloading tokenizers-0.11.6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/python/3.10/lib/python3.10/site-packages (from pyarrow==8.0.0) (1.25.2)\n",
      "Requirement already satisfied: filelock in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (3.17.0)\n",
      "Requirement already satisfied: requests in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub==0.12.0) (24.2)\n",
      "Collecting dill<0.3.6 (from datasets==2.4.0)\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: pandas in /opt/python/3.10/lib/python3.10/site-packages (from datasets==2.4.0) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /opt/python/3.10/lib/python3.10/site-packages (from datasets==2.4.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/python/3.10/lib/python3.10/site-packages (from datasets==2.4.0) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /opt/python/3.10/lib/python3.10/site-packages (from datasets==2.4.0) (3.9.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/python/3.10/lib/python3.10/site-packages (from datasets==2.4.0) (0.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/python/3.10/lib/python3.10/site-packages (from transformers==4.20.1) (2024.11.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/python/3.10/lib/python3.10/site-packages (from aiohttp->datasets==2.4.0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/python/3.10/lib/python3.10/site-packages (from requests->huggingface-hub==0.12.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/python/3.10/lib/python3.10/site-packages (from requests->huggingface-hub==0.12.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/python/3.10/lib/python3.10/site-packages (from requests->huggingface-hub==0.12.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/python/3.10/lib/python3.10/site-packages (from requests->huggingface-hub==0.12.0) (2025.1.31)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.4.0)\n",
      "  Using cached multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "  Using cached multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/python/3.10/lib/python3.10/site-packages (from pandas->datasets==2.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/python/3.10/lib/python3.10/site-packages (from pandas->datasets==2.4.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/python/3.10/lib/python3.10/site-packages (from pandas->datasets==2.4.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/python/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.4.0) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/python/3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets==2.4.0) (0.3.0)\n",
      "Downloading pyarrow-8.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.11.6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, pyarrow, fsspec, dill, multiprocess, huggingface-hub, transformers, datasets\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.10.0\n",
      "    Uninstalling fsspec-2023.10.0:\n",
      "      Successfully uninstalled fsspec-2023.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.6\n",
      "    Uninstalling dill-0.3.6:\n",
      "      Successfully uninstalled dill-0.3.6\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.14\n",
      "    Uninstalling multiprocess-0.70.14:\n",
      "      Successfully uninstalled multiprocess-0.70.14\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.32.3\n",
      "    Uninstalling huggingface-hub-0.32.3:\n",
      "      Successfully uninstalled huggingface-hub-0.32.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.9.0\n",
      "    Uninstalling datasets-2.9.0:\n",
      "      Successfully uninstalled datasets-2.9.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 fsspec-2023.5.0 huggingface-hub-0.12.0 multiprocess-0.70.13 pyarrow-8.0.0 tokenizers-0.11.6 transformers-4.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "  pyarrow==8.0.0 \\\n",
    "  fsspec==2023.5.0 \\\n",
    "  huggingface-hub==0.12.0 \\\n",
    "  datasets==2.4.0 \\\n",
    "  transformers==4.20.1 \\\n",
    "  tokenizers==0.11.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac22568-8477-4f79-b3cd-72d961d27e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch-xla (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_xla as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch-xla (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -sspec (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Package(s) not found: torch-xla\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch-xla torch_xla\n",
    "!pip show torch-xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49986b79-b85c-4b5d-9194-84746cd2718c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsspec: 2023.5.0\n",
      "pyarrow: 8.0.0\n",
      "datasets: 2.4.0\n",
      "transformers: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import fsspec, pyarrow, datasets, transformers\n",
    "print(\"fsspec:\", fsspec.__version__)\n",
    "print(\"pyarrow:\", pyarrow.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"transformers:\", transformers.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f81afbc-dc27-4ef9-a515-096075bc26e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu124\n",
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f64e45-2aff-40a0-89bc-b02b7ab4faf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x 2 jupyter jupyter 4096 Jun  2 03:24 /home/jupyter/hf_cache\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/hf_cache\n",
    "!ls -ld ~/hf_cache\n",
    "!touch ~/hf_cache/test_file && rm ~/hf_cache/test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d697fb-3e68-46dd-a309-b503dde073f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = os.path.expanduser(\"~/hf_cache\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.expanduser(\"~/hf_cache\")\n",
    "os.environ.pop(\"HF_DATASETS_OFFLINE\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a76636b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:461: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfd7e66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jupyter/hf_cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ebdf6f4df6417281ce803093d8a1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"glue\", \n",
    "    \"sst2\", \n",
    "    cache_dir=os.path.expanduser(\"~/hf_cache\")\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6fe44bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d16515f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter/hf_cache/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-c7a21146d9ec441d.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c2b9de06ac4c84a85a700587d93735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfe68e1688a4453afac1e49c98b7b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func(x):\n",
    "    return tokenizer(x['sentence'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "tokenized_dataset = dataset.map(func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9d2688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3740bf1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/python/3.10/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: transformers[torch] in /opt/python/3.10/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (2.4.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (0.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/python/3.10/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/python/3.10/lib/python3.10/site-packages (from transformers[torch]) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/python/3.10/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/python/3.10/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/python/3.10/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/python/3.10/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/python/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
      "Requirement already satisfied: sympy in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/python/3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/python/3.10/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/python/3.10/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/python/3.10/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/python/3.10/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/python/3.10/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/python/3.10/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yarrow (/opt/python/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79e75b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/python/3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 67349\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12630' max='12630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12630/12630 1:22:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.429600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.202600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.185200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.190800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.166900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "Configuration saved in ./results/checkpoint-10500/config.json\n",
      "Model weights saved in ./results/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "Configuration saved in ./results/checkpoint-11000/config.json\n",
      "Model weights saved in ./results/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-11500\n",
      "Configuration saved in ./results/checkpoint-11500/config.json\n",
      "Model weights saved in ./results/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-12000\n",
      "Configuration saved in ./results/checkpoint-12000/config.json\n",
      "Model weights saved in ./results/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to ./results/checkpoint-12500\n",
      "Configuration saved in ./results/checkpoint-12500/config.json\n",
      "Model weights saved in ./results/checkpoint-12500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12630, training_loss=0.2061511721577044, metrics={'train_runtime': 4949.8839, 'train_samples_per_second': 40.819, 'train_steps_per_second': 2.552, 'total_flos': 1.3198556141715456e+16, 'train_loss': 0.2061511721577044, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d52e17-5e1d-4729-9c10-2458bb6fd24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-4.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/pytorch-gpu.2-4:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
