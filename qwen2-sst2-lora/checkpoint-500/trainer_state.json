{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8888888888888888,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 29.15114974975586,
      "learning_rate": 0.00019875666074600356,
      "loss": 0.9861,
      "step": 8
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 87.6139907836914,
      "learning_rate": 0.00019733570159857907,
      "loss": 1.1641,
      "step": 16
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 35.58747100830078,
      "learning_rate": 0.00019591474245115453,
      "loss": 0.9783,
      "step": 24
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 46.301116943359375,
      "learning_rate": 0.00019449378330373002,
      "loss": 0.7738,
      "step": 32
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 19.03059959411621,
      "learning_rate": 0.0001930728241563055,
      "loss": 0.7412,
      "step": 40
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 47.90141296386719,
      "learning_rate": 0.000191651865008881,
      "loss": 0.6205,
      "step": 48
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 40.152259826660156,
      "learning_rate": 0.00019023090586145648,
      "loss": 0.7446,
      "step": 56
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 40.931514739990234,
      "learning_rate": 0.00018880994671403197,
      "loss": 0.6273,
      "step": 64
    },
    {
      "epoch": 0.128,
      "grad_norm": 69.67351531982422,
      "learning_rate": 0.00018738898756660749,
      "loss": 0.6423,
      "step": 72
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 37.76213073730469,
      "learning_rate": 0.00018596802841918295,
      "loss": 0.4578,
      "step": 80
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 152.06008911132812,
      "learning_rate": 0.00018454706927175843,
      "loss": 0.8715,
      "step": 88
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 54.05868148803711,
      "learning_rate": 0.00018312611012433395,
      "loss": 0.5117,
      "step": 96
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 35.963069915771484,
      "learning_rate": 0.00018170515097690944,
      "loss": 0.4105,
      "step": 104
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 44.2626953125,
      "learning_rate": 0.0001802841918294849,
      "loss": 0.6701,
      "step": 112
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 25.549100875854492,
      "learning_rate": 0.0001788632326820604,
      "loss": 0.6828,
      "step": 120
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 21.78646469116211,
      "learning_rate": 0.0001774422735346359,
      "loss": 0.4987,
      "step": 128
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 20.876842498779297,
      "learning_rate": 0.00017602131438721136,
      "loss": 0.4125,
      "step": 136
    },
    {
      "epoch": 0.256,
      "grad_norm": 10.814919471740723,
      "learning_rate": 0.00017460035523978685,
      "loss": 0.4586,
      "step": 144
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 0.8945131301879883,
      "learning_rate": 0.00017317939609236236,
      "loss": 0.1277,
      "step": 152
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.9210944175720215,
      "learning_rate": 0.00017175843694493785,
      "loss": 0.5368,
      "step": 160
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 7.3726677894592285,
      "learning_rate": 0.0001703374777975133,
      "loss": 0.2783,
      "step": 168
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 25.22506332397461,
      "learning_rate": 0.00016891651865008883,
      "loss": 0.6678,
      "step": 176
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 23.09558868408203,
      "learning_rate": 0.00016749555950266431,
      "loss": 0.5045,
      "step": 184
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 18.932836532592773,
      "learning_rate": 0.00016607460035523977,
      "loss": 0.4716,
      "step": 192
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 54.22215270996094,
      "learning_rate": 0.0001646536412078153,
      "loss": 0.4012,
      "step": 200
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 19.967252731323242,
      "learning_rate": 0.00016323268206039078,
      "loss": 0.3467,
      "step": 208
    },
    {
      "epoch": 0.384,
      "grad_norm": 17.947147369384766,
      "learning_rate": 0.00016181172291296626,
      "loss": 0.4389,
      "step": 216
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 5.866796970367432,
      "learning_rate": 0.00016039076376554175,
      "loss": 0.2986,
      "step": 224
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 44.043983459472656,
      "learning_rate": 0.00015896980461811724,
      "loss": 0.2426,
      "step": 232
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 13.146349906921387,
      "learning_rate": 0.00015754884547069273,
      "loss": 0.3123,
      "step": 240
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 6.843648433685303,
      "learning_rate": 0.00015612788632326821,
      "loss": 0.2509,
      "step": 248
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 10.66215705871582,
      "learning_rate": 0.0001547069271758437,
      "loss": 0.4377,
      "step": 256
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 2.7859866619110107,
      "learning_rate": 0.0001532859680284192,
      "loss": 0.4606,
      "step": 264
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 21.793275833129883,
      "learning_rate": 0.00015186500888099468,
      "loss": 0.2933,
      "step": 272
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 34.70711898803711,
      "learning_rate": 0.00015044404973357017,
      "loss": 0.5194,
      "step": 280
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.8494821786880493,
      "learning_rate": 0.00014902309058614565,
      "loss": 0.3508,
      "step": 288
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 40.75185775756836,
      "learning_rate": 0.00014760213143872114,
      "loss": 0.3461,
      "step": 296
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 2.967088222503662,
      "learning_rate": 0.00014618117229129663,
      "loss": 0.6,
      "step": 304
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 25.655637741088867,
      "learning_rate": 0.00014476021314387212,
      "loss": 0.3567,
      "step": 312
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 2.892897844314575,
      "learning_rate": 0.0001433392539964476,
      "loss": 0.1547,
      "step": 320
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 11.334778785705566,
      "learning_rate": 0.0001419182948490231,
      "loss": 0.3438,
      "step": 328
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.15580010414123535,
      "learning_rate": 0.00014049733570159858,
      "loss": 0.2263,
      "step": 336
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 1.8002104759216309,
      "learning_rate": 0.00013907637655417407,
      "loss": 0.1708,
      "step": 344
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 11.203950881958008,
      "learning_rate": 0.00013765541740674955,
      "loss": 0.2371,
      "step": 352
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4549617767333984,
      "learning_rate": 0.00013623445825932507,
      "loss": 0.548,
      "step": 360
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 0.41362810134887695,
      "learning_rate": 0.00013481349911190053,
      "loss": 0.1989,
      "step": 368
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 8.878938674926758,
      "learning_rate": 0.00013339253996447602,
      "loss": 0.4865,
      "step": 376
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 50.52114486694336,
      "learning_rate": 0.00013197158081705153,
      "loss": 0.8141,
      "step": 384
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 19.517988204956055,
      "learning_rate": 0.000130550621669627,
      "loss": 0.2273,
      "step": 392
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 3.0872654914855957,
      "learning_rate": 0.00012912966252220248,
      "loss": 0.1928,
      "step": 400
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 23.655908584594727,
      "learning_rate": 0.000127708703374778,
      "loss": 0.2256,
      "step": 408
    },
    {
      "epoch": 0.7395555555555555,
      "grad_norm": 18.9208984375,
      "learning_rate": 0.00012628774422735348,
      "loss": 0.1011,
      "step": 416
    },
    {
      "epoch": 0.7537777777777778,
      "grad_norm": 16.356399536132812,
      "learning_rate": 0.00012486678507992894,
      "loss": 0.3515,
      "step": 424
    },
    {
      "epoch": 0.768,
      "grad_norm": 28.297103881835938,
      "learning_rate": 0.00012344582593250443,
      "loss": 0.249,
      "step": 432
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 21.77341079711914,
      "learning_rate": 0.00012202486678507993,
      "loss": 0.2522,
      "step": 440
    },
    {
      "epoch": 0.7964444444444444,
      "grad_norm": 46.82615280151367,
      "learning_rate": 0.00012060390763765543,
      "loss": 0.4201,
      "step": 448
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.5603654384613037,
      "learning_rate": 0.00011918294849023091,
      "loss": 0.4064,
      "step": 456
    },
    {
      "epoch": 0.8248888888888889,
      "grad_norm": 4.974957466125488,
      "learning_rate": 0.0001177619893428064,
      "loss": 0.2024,
      "step": 464
    },
    {
      "epoch": 0.8391111111111111,
      "grad_norm": 0.08399397134780884,
      "learning_rate": 0.0001163410301953819,
      "loss": 0.1707,
      "step": 472
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 5.2648797035217285,
      "learning_rate": 0.00011492007104795737,
      "loss": 0.1913,
      "step": 480
    },
    {
      "epoch": 0.8675555555555555,
      "grad_norm": 2.1909918785095215,
      "learning_rate": 0.00011349911190053286,
      "loss": 0.3628,
      "step": 488
    },
    {
      "epoch": 0.8817777777777778,
      "grad_norm": 0.07453923672437668,
      "learning_rate": 0.00011207815275310836,
      "loss": 0.1842,
      "step": 496
    }
  ],
  "logging_steps": 8,
  "max_steps": 1126,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4411183595520000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
