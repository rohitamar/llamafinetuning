{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d90307-bfe2-4ca4-9f05-cf9b64361a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "\n",
    "CHECKPOINT_PATH = \"./results/checkpoint-12500\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(CHECKPOINT_PATH, num_labels=2)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a85c275-860d-450d-88d3-130c0f5b9cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0309164-81b9-47c6-9786-beff0eab8ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/jupyter/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7b6028f79245bdb2795498b64f9a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "\n",
    "def tokenize_func(x):\n",
    "    return tokenizer(x['sentence'], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "tokenized_dataset = val.map(tokenize_func, batched=True)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "dataloader = DataLoader(tokenized_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe38d1e-1be0-44b9-aa8e-88d69bf6d8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "472d2b91-afaa-4f2f-afb6-33623ea0f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Validation Accuracy: 91.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "preds, labels = [], []\n",
    "for batch in dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    label = batch['label'].to(device)\n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "    preds.extend(pred.cpu().numpy().tolist())\n",
    "    labels.extend(label.cpu().numpy().tolist())\n",
    "    \n",
    "acc = accuracy_score(labels, preds)\n",
    "print(f\"SST-2 Validation Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e30b80c3-c495-43e9-9919-ed1fc8c5eaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sentence(sentence):\n",
    "    tokenized = tokenizer(\n",
    "        [sentence],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    input_ids, attention_mask = tokenized['input_ids'], tokenized['attention_mask']\n",
    "    input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    prediction = torch.argmax(logits, dim=-1).cpu().numpy().tolist()[0]\n",
    "    confidence = torch.softmax(logits, dim=-1).cpu().numpy().tolist()[0]\n",
    "    conf_value = confidence[prediction]\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(f\"Sentiment of sentence was positive with confidence {conf_value * 100}\")\n",
    "    else:\n",
    "        print(f\"Sentiment of sentence was negative with confidence {conf_value * 100}\")\n",
    "        \n",
    "    return prediction, conf_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71397473-e89c-47e5-adb3-ba1c6278b5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of sentence was positive with confidence 98.73080849647522\n"
     ]
    }
   ],
   "source": [
    "pred, confidence = predict_sentence('I absolutely loved that movie!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd118136-8a78-423b-8b91-3c49fa9d38f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of sentence was negative with confidence 99.87925291061401\n"
     ]
    }
   ],
   "source": [
    "pred, confidence = predict_sentence('That movie was terrible, what was that, not sure what the director was thinking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58abcb36-3336-4ae2-893a-deec95de7992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of sentence was negative with confidence 96.30213975906372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.9630213975906372)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence('Hmm, what do you want to eat today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e61ee0f-76c4-4e18-a666-82211dfc66bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of sentence was negative with confidence 90.63577055931091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.9063577055931091)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence('What\\'s the weather like tomorrow?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0526da35-2852-44ad-82d7-d0a3a2cf5c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of sentence was negative with confidence 79.75066304206848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.7975066304206848)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence('Eh, yeah that movie was okay. It wasn\\'t bad, but definitely not going to watch that again')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-4.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/pytorch-gpu.2-4:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
